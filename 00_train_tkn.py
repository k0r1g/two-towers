'''
We're going to start doing one full loop (tokeniser, w2v, dual encoder) with just the first 1000 rows. Then we'll do the full loop. 

'''



# ---------- Step 1: Tokenise the data ----------


from datasets import load_dataset

ds = load_dataset("microsoft/ms_marco", "v1.1")







# ---------- Step 1: Tokenise the data ----------




# ---------- Step 1: Tokenise the data ----------





# ---------- Step 1: Tokenise the data ----------





# ---------- Step 1: Tokenise the data ----------




# ---------- Step 1: Tokenise the data ----------




